---
title: MemOS ç¤ºä¾‹
desc: "æ­å–œä½ â€”â€”ä½ å·²ç»æŒæ¡äº†å¿«é€Ÿå…¥é—¨å¹¶æ„å»ºäº†ç¬¬ä¸€ä¸ªå¯ç”¨çš„è®°å¿†ï¼ç°åœ¨æ˜¯æ—¶å€™é€šè¿‡ç»“åˆä¸åŒçš„è®°å¿†ç±»å‹å’ŒåŠŸèƒ½ï¼Œçœ‹çœ‹ MemOS å¯ä»¥å®ç°å¤šå¤§çš„å¯èƒ½æ€§ã€‚ä½¿ç”¨è¿™äº›ç²¾é€‰ç¤ºä¾‹æ¥æ¿€å‘ä½ è‡ªå·±çš„æ™ºèƒ½ä½“ã€èŠå¤©æœºå™¨äººæˆ–çŸ¥è¯†ç³»ç»Ÿçš„çµæ„Ÿã€‚"
---

::card-group

  :::card
  ---
  icon: ri:play-line
  title: æœ€ç®€Pipeline 
  to: /cn/open_source/getting_started/examples#ç¤ºä¾‹-1æœ€ç®€pipeline
  ---
  æœ€å°çš„å¯ç”¨Pipeline  â€” æ·»åŠ ã€æœç´¢æ˜æ–‡è®°å¿†ã€‚
  :::

  :::card
  ---
  icon: ri:tree-line
  title: å¤šä¿¡æ¯æºçš„æ·»åŠ ä¸æ£€ç´¢
  to: /cn/open_source/getting_started/examples#ç¤ºä¾‹-2å¤šä¿¡æ¯æºè®°å¿†çš„æ·»åŠ ä¸æ£€ç´¢
  ---
  æ·»åŠ æ–‡æœ¬ã€å›¾ç‰‡ã€æ–‡ä»¶ã€å·¥å…·è°ƒç”¨çš„å¤šä¿¡æ¯æºmessagesåˆ°è®°å¿†ï¼Œå¹¶èƒ½å¤Ÿæ£€ç´¢å®ƒä»¬ã€‚
  :::

  :::card
  ---
  icon: ri:apps-line
  title: å¤šCubeæ·»åŠ å’Œæ£€ç´¢
  to: /cn/open_source/getting_started/examples#ç¤ºä¾‹-3å¤šcubeæ·»åŠ å’Œæ£€ç´¢
  ---
  æ·»åŠ ä¸åŒè®°å¿†åˆ°ä¸åŒçš„Cubeï¼Œåœ¨æ£€ç´¢æ—¶åŒæ—¶å¬å›å®ƒä»¬ã€‚
  :::

  :::card
  ---
  icon: ri:database-2-line
  title: ä»… KVCacheMemory
  to: /cn/open_source/getting_started/examples#ç¤ºä¾‹-4ä»…-kvcachememory
  ---
  ä½¿ç”¨çŸ­æœŸ KV cacheåŠ é€Ÿä¼šè¯ï¼Œå®ç°å¿«é€Ÿä¸Šä¸‹æ–‡æ³¨å…¥ã€‚
  :::

  :::card
  ---
  icon: ri:calendar-check-line
  title: è®°å¿†è°ƒåº¦
  to: /cn/open_source/getting_started/examples#ç¤ºä¾‹-5å¤šå¿†è°ƒåº¦
  ---
  ä¸ºå¤šç”¨æˆ·ã€å¤šä¼šè¯æ™ºèƒ½ä½“è¿è¡ŒåŠ¨æ€è®°å¿†è°ƒç”¨ã€‚
  :::

::

## ç¤ºä¾‹ 1ï¼šæœ€ç®€Pipeline

### ä½•æ—¶ä½¿ç”¨ï¼š
- ä½ æƒ³è¦æœ€å°çš„å…¥é—¨å¯ç”¨ç¤ºä¾‹ã€‚
- ä½ åªéœ€è¦å°†ç®€å•çš„æ˜æ–‡è®°å¿†å­˜å‚¨åˆ°æ•°æ®åº“ä¸­ï¼Œå¹¶èƒ½å¤Ÿæ£€ç´¢å®ƒä»¬ã€‚

### å…³é”®ç‚¹ï¼š
- æ”¯æŒåŸºç¡€çš„ä¸ªäººç”¨æˆ·è®°å¿†æ·»åŠ ã€æœç´¢ã€‚

### å®Œæ•´ç¤ºä¾‹ä»£ç 
```python
import json
from memos.api.routers.server_router import add_memories, search_memories
from memos.api.product_models import APIADDRequest, APISearchRequest

user_id = "test_user_1"
add_req = APIADDRequest(
    user_id=user_id,
    writable_cube_ids=["cube_test_user_1"],
    messages = [
      {"role": "user", "content": "Iâ€™ve planned to travel to Guangzhou during the summer vacation. What chain hotels are available for accommodation?"},
      {"role": "assistant", "content": "You can consider [7 Days Inn, Ji Hotel, Hilton], etc."},
      {"role": "user", "content": "Iâ€™ll choose 7 Days Inn."},
      {"role": "assistant", "content": "Okay, feel free to ask me if you have any other questions."}
    ],
    async_mode="sync",
    mode="fine",
)

add_rsp = add_memories(add_req)
print("add_memories rsp: \n\n", add_rsp)

search_req = APISearchRequest(
    user_id=user_id,
    readable_cube_ids=["cube_test_user_1"],
    query="Please recommend a hotel that I havenâ€™t stayed at before.",
    include_preference=True,
)

search_rsp = search_memories(search_req).data
print("\n\nsearch_rsp: \n\n", json.dumps(search_rsp, indent=2, ensure_ascii=False))
````

## ç¤ºä¾‹ 2ï¼šå¤šä¿¡æ¯æºè®°å¿†çš„æ·»åŠ ä¸æ£€ç´¢

### ä½•æ—¶ä½¿ç”¨ï¼š

- é™¤å•çº¯çš„æ–‡æœ¬å¯¹è¯å¤–ï¼Œä½ éœ€è¦å°†æ–‡ä»¶ã€å›¾ç‰‡å†…å®¹æˆ–å·¥å…·è°ƒç”¨å†å²ä¿¡æ¯åŠ å…¥è®°å¿†
- åŒæ—¶ä½ æƒ³è¦æ£€ç´¢è¿™äº›å¤šæºä¿¡æ¯çš„è®°å¿†

### å…³é”®ç‚¹ï¼š

- å¤šç§ä¿¡æ¯æ¥æºçš„è®°å¿†æ·»åŠ 
- éœ€è¦æœ‰å¯ä¸‹è½½çš„æ–‡ä»¶ã€å›¾ç‰‡url
- æ·»åŠ çš„ä¿¡æ¯éœ€è¦ä¸¥æ ¼ç¬¦åˆOpenAI Messagesæ ¼å¼
- system promptä¸­çš„å·¥å…·Schemaéœ€è¦åŒ…è£…åœ¨<tool_chema> </tool_schema>ä¸­

### å®Œæ•´ç¤ºä¾‹ä»£ç 
æ·»åŠ æ–‡æœ¬+æ–‡ä»¶åˆ°è®°å¿†ä¸­
```python
import json
from memos.api.routers.server_router import add_memories, search_memories
from memos.api.product_models import APIADDRequest, APISearchRequest

user_id = "test_user_2"
add_req = APIADDRequest(
    user_id=user_id,
    writable_cube_ids=["cube_test_user_2"],
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Please read this file, summarize the key points, and provide a final conclusion."
                },
                {
                    "type": "file",
                    "file": {
                    "file_id": "file_123",
                    "filename": "report.md",
                    "file_data": "@http://139.196.232.20:9090/graph-test/algorithm/2025_11_13/1763043889_1763043782_PM1%E8%BD%A6%E9%97%B4PMT%E9%9D%B4%E5%8E%8B%E8%BE%B9%E5%8E%8B%E5%8E%8B%E5%8A%9B%E6%97%A0%E6%B3%95%E5%BB%BA%E7%AB%8B%E6%95%85%E9%9A%9C%E6%8A%A5%E5%91%8A20240720.md"
                    }
                },
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "Final Summary: During the PMT boot-pressure startup test of the PM1 workshop on July 20, 2024, the drive could not run because the edge pressures on both sides failed to reach the 2.5-bar interlock requirement. After troubleshooting, the PLC output signals, hydraulic pipelines, and valves were all found to be normal. The root cause was ultimately identified as poor contact at the negative terminal of the proportional valveâ€™s DC 24V power supply inside the PLC cabinet, caused by a short-jumpered terminal block. After re-connecting the negative incoming lines in parallel, the equipment returned to normal operation. It is recommended to replace terminal blocks in batches, inspect instruments with uncertain service life, and optimize the troubleshooting process by tracing common-mode issues from shared buses and power supply sources."
                }
            ]
        }
    ],
    async_mode="sync",
    mode="fine",
)

add_rsp = add_memories(add_req)
print("add_memories rsp: \n\n", add_rsp)

search_req = APISearchRequest(
    user_id=user_id,
    readable_cube_ids=["cube_test_user_2"],
    query="Workshop PMT boot pressure startup test",
    include_preference=False,
)
search_rsp = search_memories(search_req).data
print("\n\nsearch_rsp: \n\n", json.dumps(search_rsp, indent=2, ensure_ascii=False))
```
æ·»åŠ å¤šç§æ··åˆä¿¡æ¯æºçš„messagesåˆ°è®°å¿†ä¸­
```python
import json
from memos.api.routers.server_router import add_memories, search_memories
from memos.api.product_models import APIADDRequest, APISearchRequest

user_id = "test_user_2"
add_req = APIADDRequest(
    user_id=user_id,
    writable_cube_ids=["cube_test_user_2"],
    messages = [
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "You are a professional industrial fault analysis assistant. Please read the PDF, images, and instructions provided by the user and provide a professional technical summary.\n\n<tool_schema>\n[\n  {\n    \"name\": \"file_reader\",\n    \"description\": \"Used to read the content of files uploaded by the user and return the text data (in JSON string format).\",\n    \"parameters\": [\n      {\"name\": \"file_id\", \"type\": \"string\", \"required\": true, \"description\": \"The file ID to be read\"}\n    ],\n    \"returns\": {\"type\": \"text\", \"description\": \"Returns the extracted text content of the file\"}\n  }\n]\n</tool_schema>"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "type": "text",
        "text": "Please read this file and image, summarize the key points, and provide a final conclusion."
      },
      {
        "type": "file",
        "file": {
          "file_id": "file_123",
          "filename": "report.pdf",
          "file_data": "@http://139.196.232.20:9090/graph-test/algorithm/2025_11_13/1763043889_1763043782_PM1%E8%BD%A6%E9%97%B4PMT%E9%9D%B4%E5%8E%8B%E8%BE%B9%E5%8E%8B%E5%8E%8B%E5%8A%9B%E6%97%A0%E6%B3%95%E5%BB%BA%E7%AB%8B%E6%95%85%E9%9A%9C%E6%8A%A5%E5%91%8A20240720.md"
        }
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "https://play-groud-test-1.oss-cn-shanghai.aliyuncs.com/%E5%9B%BE%E7%89%871.jpeg"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "id": "call_file_reader_001",
        "type": "function",
        "function": {
          "name": "file_reader",
          "arguments": "{\"file_id\": \"file_123\"}"
        }
      }
    ]
  },
  {
    "role": "tool",
    "tool_call_id": "call_file_reader_001",
    "content": [
      {
        "type": "text",
        "text": "{\"file_id\":\"file_123\",\"extracted_text\":\"PM1 workshop PMT boot pressure startup test recordâ€¦ Final fault cause: poor contact at the negative terminal of the DC 24V power supply circuit due to a short-jumped terminal block.\"}"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "Final Summary: During the PMT boot-pressure startup test of the PM1 workshop on July 20, 2024, the drive could not run because the edge pressures on both sides failed to reach the 2.5-bar interlock requirement. After troubleshooting, the PLC output signals, hydraulic pipelines, and valves were all found to be normal. The root cause was ultimately identified as poor contact at the negative terminal of the proportional valveâ€™s DC 24V power supply inside the PLC cabinet, caused by a short-jumpered terminal block. After re-connecting the negative incoming lines in parallel, the equipment returned to normal operation. It is recommended to replace terminal blocks in batches, inspect instruments with uncertain service life, and optimize the troubleshooting process by tracing common-mode issues from shared buses and power supply sources."
      }
    ]
  }
],
    async_mode="sync",
    mode="fine",
)

add_rsp = add_memories(add_req)

print("add_memories rsp: \n\n", add_rsp)



search_req = APISearchRequest(
    user_id=user_id,
    readable_cube_ids=["cube_test_user_2"],
    query="Workshop PMT boot pressure startup test",
    include_preference=False,
)

search_rsp = search_memories(search_req).data
print("\n\nsearch_rsp: \n\n", json.dumps(search_rsp, indent=2, ensure_ascii=False))
```

## ç¤ºä¾‹ 3ï¼šå¤šCubeæ·»åŠ å’Œæ£€ç´¢

### ä½•æ—¶ä½¿ç”¨ï¼š

- å‘å½¼æ­¤éš”ç¦»çš„ä¸åŒçš„Cubeç©ºé—´ä¸­æ·»åŠ è®°å¿†
- ä½ å¸Œæœ›åŒæ—¶æ£€ç´¢ä¸åŒCubeç©ºé—´ä¸­çš„è®°å¿†

### å…³é”®ç‚¹ï¼š

- åœ¨æ£€ç´¢æ—¶è¾“å…¥å«æœ‰å¤šä¸ªcube idçš„readable_cube_idsåˆ—è¡¨

### å®Œæ•´ç¤ºä¾‹ä»£ç 
```python
import json
from memos.api.routers.server_router import add_memories, search_memories
from memos.api.product_models import APIADDRequest, APISearchRequest

user_id = "test_user_3"
add_req = APIADDRequest(
    user_id=user_id,
    writable_cube_ids=["cube_test_user_3_1"] ,
    messages = [
      {"role": "user", "content": "Iâ€™ve planned to travel to Guangzhou during the summer vacation. What chain hotels are available for accommodation?"},
      {"role": "assistant", "content": "You can consider [7 Days Inn, Ji Hotel, Hilton], etc."},
      {"role": "user", "content": "Iâ€™ll choose 7 Days Inn."},
      {"role": "assistant", "content": "Okay, feel free to ask me if you have any other questions."}
    ],
    async_mode="sync",
    mode="fine",
)

add_rsp = add_memories(add_req)
print("add_memories rsp: \n\n", add_rsp)

add_req = APIADDRequest(
    user_id=user_id,
    writable_cube_ids=["cube_test_user_3_2"] ,
    messages = [
      {"role": "user", "content": "I love you, I need you."},
      {"role": "assistant", "content": "Wow, I love you too"},
    ],
    async_mode="sync",
    mode="fine",
)

add_rsp = add_memories(add_req)
print("add_memories rsp: \n\n", add_rsp)

search_req = APISearchRequest(
    user_id=user_id,
    readable_cube_ids=["cube_test_user_3_1", "cube_test_user_3_2"],
    query="Please recommend a hotel, Love u u",
    include_preference=True,
)

search_rsp = search_memories(search_req).data
print("\n\nsearch_rsp: \n\n", json.dumps(search_rsp, indent=2, ensure_ascii=False))
```

## ç¤ºä¾‹ 4ï¼šä»… KVCacheMemory

### ä½•æ—¶ä½¿ç”¨ï¼š

- ä½ æƒ³è¦çŸ­æœŸå·¥ä½œè®°å¿†ä»¥åŠ å¿«å¤šè½®å¯¹è¯é€Ÿåº¦ã€‚
- é€‚åˆèŠå¤©æœºå™¨äººä¼šè¯åŠ é€Ÿæˆ–æç¤ºå¤ç”¨ã€‚
- æœ€é€‚åˆç¼“å­˜éšè—çŠ¶æ€ / KV å¯¹ã€‚

### å…³é”®ç‚¹ï¼š

- ä½¿ç”¨ KVCacheMemoryï¼Œä¸å«æ˜¾å¼æ˜æ–‡è®°å¿†ã€‚
- æ¼”ç¤ºæå– â†’ æ·»åŠ  â†’ åˆå¹¶ â†’ è·å– â†’ åˆ é™¤ã€‚
- å±•ç¤ºå¦‚ä½•å¯¼å‡º/åŠ è½½ KV cacheã€‚

### å®Œæ•´ç¤ºä¾‹ä»£ç 


```python
import json
from transformers import DynamicCache

from memos.memories.activation.item import KVCacheItem
from memos.configs.memory import MemoryConfigFactory
from memos.memories.factory import MemoryFactory

def get_cache_info(cache):
    if not cache:
        return None

    num_layers = 0
    total_size_bytes = 0

    if hasattr(cache, "layers"):
        num_layers = len(cache.layers)
        for layer in cache.layers:
            if hasattr(layer, "key_cache") and layer.key_cache is not None:
                total_size_bytes += layer.key_cache.nelement() * layer.key_cache.element_size()
            if hasattr(layer, "value_cache") and layer.value_cache is not None:
                total_size_bytes += layer.value_cache.nelement() * layer.value_cache.element_size()

            if hasattr(layer, "keys") and layer.keys is not None:
                total_size_bytes += layer.keys.nelement() * layer.keys.element_size()
            if hasattr(layer, "values") and layer.values is not None:
                total_size_bytes += layer.values.nelement() * layer.values.element_size()

    elif hasattr(cache, "key_cache") and hasattr(cache, "value_cache"):
        num_layers = len(cache.key_cache)
        for k, v in zip(cache.key_cache, cache.value_cache, strict=False):
            if k is not None:
                total_size_bytes += k.nelement() * k.element_size()
            if v is not None:
                total_size_bytes += v.nelement() * v.element_size()

    return {
        "num_layers": num_layers,
        "size_bytes": total_size_bytes,
        "size_mb": f"{total_size_bytes / (1024 * 1024):.2f} MB",
    }


def serialize_item(obj):
    if isinstance(obj, list):
        return [serialize_item(x) for x in obj]

    if isinstance(obj, KVCacheItem):
        return {
            "id": obj.id,
            "metadata": obj.metadata,
            "records": obj.records.model_dump()
            if hasattr(obj.records, "model_dump")
            else obj.records,
            "memory": get_cache_info(obj.memory),
        }

    if isinstance(obj, DynamicCache):
        return get_cache_info(obj)

    return str(obj)


# ä¸º KVCacheMemory(HuggingFace åç«¯)åˆ›å»ºé…ç½®
config = MemoryConfigFactory(
    backend="kv_cache",
    config={
        "extractor_llm": {
            "backend": "huggingface",
            "config": {
                "model_name_or_path": "Qwen/Qwen3-0.6B",
                "max_tokens": 32,
                "add_generation_prompt": True,
                "remove_think_prefix": True,
            },
        },
    },
)

# å®ä¾‹åŒ– KVCacheMemory
kv_mem = MemoryFactory.from_config(config)

# æå–ä¸€ä¸ª KVCacheItem(DynamicCache)
prompt = [
    {"role": "user", "content": "What is MemOS?"},
    {"role": "assistant", "content": "MemOS is a memory operating system for LLMs."},
]
print("===== Extract KVCacheItem =====")
cache_item = kv_mem.extract(prompt)
print(json.dumps(serialize_item(cache_item), indent=2, default=str))

# å°†ç¼“å­˜æ·»åŠ åˆ°å†…å­˜ä¸­
kv_mem.add([cache_item])
print("All caches:")
print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))

# é€šè¿‡ ID è·å–
retrieved = kv_mem.get(cache_item.id)
print("Retrieved:")
print(json.dumps(serialize_item(retrieved), indent=2, default=str))

# åˆå¹¶ç¼“å­˜
item2 = kv_mem.extract([{"role": "user", "content": "Tell me a joke."}])
kv_mem.add([item2])
merged = kv_mem.get_cache([cache_item.id, item2.id])
print("Merged cache:")
print(json.dumps(serialize_item(merged), indent=2, default=str))

# åˆ é™¤å…¶ä¸­ä¸€ä¸ª
kv_mem.delete([cache_item.id])
print("After delete:")
print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))

# å¯¼å‡ºå’ŒåŠ è½½ç¼“å­˜
kv_mem.dump("tmp/kv_mem")
print("Dumped to tmp/kv_mem")
kv_mem.delete_all()
kv_mem.load("tmp/kv_mem")
print("Loaded caches:")
print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))
```

## ç¤ºä¾‹ 5ï¼šè®°å¿†è°ƒåº¦

### ä½•æ—¶ä½¿ç”¨ï¼š

- ä½ å¸Œæœ›ç®¡ç†å¤šä¸ªç”¨æˆ·ã€å¤šä¸ª MemCube æˆ–åŠ¨æ€çš„è®°å¿†æµã€‚
- é€‚ç”¨äº SaaS æ™ºèƒ½ä½“æˆ–å¤šä¼šè¯ LLMã€‚
- å±•ç¤º MemScheduler ä¸ YAML é…ç½®èƒ½åŠ›ã€‚

### å…³é”®ç‚¹ï¼š

- ä½¿ç”¨ parse\_yaml åŠ è½½ MOSConfig å’Œ MemCubeConfigã€‚
- åŠ¨æ€åˆ›å»ºç”¨æˆ·ä¸ MemCubeã€‚
- å±•ç¤ºè®°å¿†çš„è¿è¡Œæ—¶è°ƒåº¦ã€‚

### å®Œæ•´ç¤ºä¾‹ä»£ç 

```python
import shutil
import uuid
from pathlib import Path

from memos.configs.mem_cube import GeneralMemCubeConfig
from memos.configs.mem_os import MOSConfig
from memos.mem_cube.general import GeneralMemCube
from memos.mem_os.main import MOS
from memos.mem_scheduler.schemas.message_schemas import ScheduleMessageItem
from memos.mem_scheduler.utils.db_utils import get_utc_now
from memos.mem_scheduler.utils.misc_utils import parse_yaml
from memos.mem_scheduler.schemas.task_schemas import (
    ANSWER_TASK_LABEL,
    MEM_UPDATE_TASK_LABEL,
    QUERY_TASK_LABEL,
)

# ä½¿ç”¨ MemScheduler åŠ è½½ä¸» MOSï¼ˆMemory-Oriented Systemï¼‰é…ç½®æ–‡ä»¶
config = parse_yaml(
    f"./examples/data/config/mem_scheduler/memos_config_w_scheduler.yaml"
)
# å°†è§£æå‡ºçš„é…ç½®å­—å…¸ä¼ å…¥ MOSConfig æ„é€ å™¨ï¼Œæ„å»ºé…ç½®å¯¹è±¡
mos_config = MOSConfig(**config)
# ä½¿ç”¨é…ç½®å¯¹è±¡åˆå§‹åŒ– MOS ç³»ç»Ÿå®ä¾‹
mos = MOS(mos_config)

# ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„åŠ¨æ€ç”¨æˆ· IDï¼ˆä½¿ç”¨ UUID4ï¼‰
user_id = str(uuid.uuid4())
# åœ¨ MOS ç³»ç»Ÿä¸­ä¸ºè¯¥ç”¨æˆ·åˆ›å»ºè´¦æˆ·
mos.create_user(user_id=user_id)

# ä» YAML æ–‡ä»¶åŠ è½½ MemCubeï¼ˆè®°å¿†ç«‹æ–¹ä½“ï¼‰çš„é€šç”¨é…ç½®
config = GeneralMemCubeConfig.from_yaml_file(
    f"./examples/data/config/mem_scheduler/mem_cube_config.yaml"
)
# å®šä¹‰ MemCube çš„å”¯ä¸€æ ‡è¯†ç¬¦
mem_cube_id = "mem_cube_5"
# å®šä¹‰ MemCube çš„æœ¬åœ°å­˜å‚¨è·¯å¾„ï¼ˆè·¯å¾„ä¸­åŒ…å«ç”¨æˆ· ID å’Œ MemCube IDï¼‰
mem_cube_name_or_path = f"./outputs/mem_scheduler/{user_id}/{mem_cube_id}"

# å¦‚æœè¯¥è·¯å¾„å·²å­˜åœ¨ï¼ˆå³ä¹‹å‰è¿è¡Œè¿‡ï¼‰ï¼Œåˆ™å…ˆåˆ é™¤æ—§ç›®å½•
if Path(mem_cube_name_or_path).exists():
    shutil.rmtree(mem_cube_name_or_path)
    print(f"{mem_cube_name_or_path} ç›®å½•éç©ºï¼Œå·²è¢«åˆ é™¤ã€‚")

# æ ¹æ®åŠ è½½çš„é…ç½®åˆ›å»ºä¸€ä¸ªæ–°çš„ MemCube å®ä¾‹
mem_cube = GeneralMemCube(config)
# å°†è¯¥ MemCube å®ä¾‹åºåˆ—åŒ–å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
mem_cube.dump(mem_cube_name_or_path)

# åœ¨ MOS ç³»ç»Ÿä¸­ä¸ºå½“å‰ç”¨æˆ·æ³¨å†Œè¿™ä¸ª MemCube
mos.register_mem_cube(
    mem_cube_name_or_path=mem_cube_name_or_path, mem_cube_id=mem_cube_id, user_id=user_id
)

# å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºè·å–ç¼“å­˜ï¼ˆå¦‚ KV Cacheï¼‰çš„å†…å­˜ä¿¡æ¯
def get_cache_info(cache):
    # å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œåˆ™ç›´æ¥è¿”å› None
    if not cache:
        return None

    num_layers = 0            # è®°å½•ç¼“å­˜çš„å±‚æ•°
    total_size_bytes = 0      # è®°å½•æ€»å­—èŠ‚æ•°

    # æƒ…å†µä¸€ï¼šç¼“å­˜ç»“æ„åŒ…å« layers å±æ€§ï¼ˆå¦‚ HuggingFace çš„ç¼“å­˜æ ¼å¼ï¼‰
    if hasattr(cache, "layers"):
        num_layers = len(cache.layers)
        for layer in cache.layers:
            # ç»Ÿè®¡ key_cache çš„å†…å­˜å ç”¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(layer, "key_cache") and layer.key_cache is not None:
                total_size_bytes += layer.key_cache.nelement() * layer.key_cache.element_size()
            # ç»Ÿè®¡ value_cache çš„å†…å­˜å ç”¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(layer, "value_cache") and layer.value_cache is not None:
                total_size_bytes += layer.value_cache.nelement() * layer.value_cache.element_size()

            # å…¼å®¹å…¶ä»–å¯èƒ½çš„ç¼“å­˜å‘½åæ–¹å¼ï¼ˆå¦‚ keys/valuesï¼‰
            if hasattr(layer, "keys") and layer.keys is not None:
                total_size_bytes += layer.keys.nelement() * layer.keys.element_size()
            if hasattr(layer, "values") and layer.values is not None:
                total_size_bytes += layer.values.nelement() * layer.values.element_size()

    # æƒ…å†µäºŒï¼šç¼“å­˜ç»“æ„ç›´æ¥åŒ…å« key_cache å’Œ value_cache åˆ—è¡¨ï¼ˆå¦‚æŸäº›è‡ªå®šä¹‰æ ¼å¼ï¼‰
    elif hasattr(cache, "key_cache") and hasattr(cache, "value_cache"):
        num_layers = len(cache.key_cache)
        for k, v in zip(cache.key_cache, cache.value_cache, strict=False):
            if k is not None:
                total_size_bytes += k.nelement() * k.element_size()
            if v is not None:
                total_size_bytes += v.nelement() * v.element_size()

    # è¿”å›ç»“æ„åŒ–çš„ç¼“å­˜ä¿¡æ¯ï¼ŒåŒ…æ‹¬å±‚æ•°ã€å­—èŠ‚æ•°å’Œä»¥ MB ä¸ºå•ä½çš„å¯è¯»æ ¼å¼
    return {
        "num_layers": num_layers,
        "size_bytes": total_size_bytes,
        "size_mb": f"{total_size_bytes / (1024 * 1024):.2f} MB",
    }

# å®šä¹‰è‡ªå®šä¹‰çš„æŸ¥è¯¢ï¼ˆqueryï¼‰å¤„ç†å‡½æ•°
def custom_query_handler(messages: list[ScheduleMessageItem]):
    for msg in messages:
        # æ‰“å°ç”¨æˆ·è¾“å…¥å†…å®¹
        print(f"\n[scheduler] ç”¨æˆ·è¾“å…¥äº†æŸ¥è¯¢ï¼š{msg.content}")
        # æ‰‹åŠ¨æ„é€ ä¸€ä¸ªå¸¦æœ‰ MEM_UPDATE æ ‡ç­¾çš„æ–°æ¶ˆæ¯ï¼Œç”¨äºè§¦å‘è®°å¿†æ›´æ–°
        new_msg = msg.model_copy(update={"label": MEM_UPDATE_TASK_LABEL})
        # å°†è¯¥æ¶ˆæ¯æäº¤ç»™è°ƒåº¦å™¨å¤„ç†
        mos.mem_scheduler.submit_messages([new_msg])

# å®šä¹‰è‡ªå®šä¹‰çš„å›ç­”ï¼ˆanswerï¼‰å¤„ç†å‡½æ•°
def custom_answer_handler(messages: list[ScheduleMessageItem]):
    for msg in messages:
        # æ‰“å° LLM çš„å›å¤å†…å®¹
        print(f"\n[scheduler] LLM å›å¤äº†ç­”æ¡ˆï¼š{msg.content}")

# å®šä¹‰è‡ªå®šä¹‰çš„è®°å¿†æ›´æ–°ï¼ˆmem_updateï¼‰å¤„ç†å‡½æ•°
def custom_mem_update_handler(messages: list[ScheduleMessageItem]):
    for msg in messages:
        mem_cube = mos.mem_cubes.get(msg.mem_cube_id)
        kv_mem = mem_cube.act_mem
        # å¦‚æœè¯¥ MemCube é…ç½®äº†æ–‡æœ¬è®°å¿†ï¼ˆTreeTextMemory / NaiveTextMemoryï¼‰
        if mem_cube and mem_cube.text_mem:
            # åœ¨æ–‡æœ¬è®°å¿†ä¸­æœç´¢ä¸å½“å‰å†…å®¹ç›¸å…³çš„è®°å¿†ï¼ˆè¿”å› top_k=3 æ¡ï¼‰
            results = mem_cube.text_mem.search(msg.content, top_k=3)
            for mem in results:
                print(f"\n[scheduler] æ£€ç´¢åˆ°çš„è®°å¿†ï¼š{mem.memory}")
                print(f"\n[scheduler] è½¬æ¢ä¸ºæ¿€æ´»è®°å¿†......")
                # ä»æ–‡æœ¬è®°å¿†ä¸­æå–å¯¹åº”çš„ KV ç¼“å­˜é¡¹
                cache_item = kv_mem.extract(mem.memory)
                # é™„åŠ å…ƒä¿¡æ¯ï¼šå…³è”çš„æ–‡æœ¬è®°å¿†å†…å®¹å’Œæ—¶é—´æˆ³
                cache_item.records.text_memories = [mem.memory]
                cache_item.records.timestamp = get_utc_now()
                # å°†è¯¥ç¼“å­˜é¡¹æ·»åŠ åˆ°æ¿€æ´»è®°å¿†ä¸­
                kv_mem.add([cache_item])
                print(f"\n[scheduler] å®Œæˆï¼")

# å°†ä¸Šè¿°ä¸‰ä¸ªè‡ªå®šä¹‰å¤„ç†å™¨æ³¨å†Œåˆ°è°ƒåº¦å™¨çš„åˆ†å‘å™¨ä¸­ï¼Œåˆ†åˆ«å¯¹åº”ä¸åŒä»»åŠ¡æ ‡ç­¾
mos.mem_scheduler.dispatcher.register_handlers(
    {
        QUERY_TASK_LABEL: custom_query_handler,        # æŸ¥è¯¢ä»»åŠ¡
        ANSWER_TASK_LABEL: custom_answer_handler,      # å›ç­”ä»»åŠ¡
        MEM_UPDATE_TASK_LABEL: custom_mem_update_handler,  # è®°å¿†æ›´æ–°ä»»åŠ¡
    }
)

# åˆå§‹æ·»åŠ ä¸¤æ¡æµ‹è¯•æ¶ˆæ¯ï¼ˆç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯ï¼‰åˆ°ç³»ç»Ÿä¸­
messages = [
    {"role": "user", "content": "I like playing football."},
    {"role": "assistant", "content": "I like playing football too."},
]
mos.add(messages, user_id=user_id, mem_cube_id=mem_cube_id)

# è¿›å…¥èŠå¤©å¾ªç¯ï¼šå±•ç¤º TreeTextMemory çš„è®°å¿†èŠ‚ç‚¹ç»“æ„ + KV Cache çš„çŠ¶æ€
while True:
    # è·å–ç”¨æˆ·è¾“å…¥å¹¶å»é™¤é¦–å°¾ç©ºæ ¼
    user_input = input("ğŸ‘¤ [You] ").strip()
    print()
    # è°ƒç”¨ MOS ç³»ç»Ÿè¿›è¡ŒèŠå¤©å“åº”
    response = mos.chat(user_input, user_id=user_id)
    # è·å–è¯¥ç”¨æˆ·å½“å‰ MemCube ä¸­çš„æ‰€æœ‰è®°å¿†å†…å®¹
    retrieved_memories = mos.get_all(mem_cube_id=mem_cube_id, user_id=user_id)

    # æ‰“å°åŠ©æ‰‹çš„å›å¤
    print(f"ğŸ¤– [Assistant] {response}")

    # è·å–æ–‡æœ¬è®°å¿†éƒ¨åˆ†ï¼ˆTreeTextMemoryï¼‰
    memories = retrieved_memories["text_mem"][0]["memories"]
    for mem in memories:
        print(f"[æ–‡æœ¬è®°å¿†] {mem.memory}")

    # è·å–å¯¹åº”çš„ MemCube å’Œå…¶æ¿€æ´»è®°å¿†ï¼ˆKV Cacheï¼‰
    mem_cube = mos.mem_scheduler.mem_cube
    kv_mem = mem_cube.act_mem
    # éå†æ‰€æœ‰æ¿€æ´»è®°å¿†é¡¹ï¼Œæ‰“å°å…¶ç¼“å­˜ä¿¡æ¯å’Œè®°å½•
    for cache_item in kv_mem.get_all():
        print(
            f"[æ¿€æ´»è®°å¿†] {get_cache_info(cache_item.memory)} ï¼ˆè®°å½•ï¼š{cache_item.records}ï¼‰"
        )
```

::note
**è¯·æ³¨æ„**<br>
ä½¿ç”¨ dump() å’Œ load() æ¥æŒä¹…åŒ–ä½ çš„è®°å¿†ç«‹æ–¹ä½“ã€‚

åŠ¡å¿…ç¡®ä¿ä½ çš„å‘é‡æ•°æ®åº“ç»´åº¦ä¸ä½ çš„åµŒå…¥å™¨åŒ¹é…ã€‚

å¦‚ä½¿ç”¨åŸºäºå›¾çš„æ˜æ–‡è®°å¿†åŠŸèƒ½ï¼Œä½ éœ€è¦å®‰è£… Neo4j Desktopã€‚
::

## ä¸‹ä¸€æ­¥

ä½ æ‰åˆšåˆšå¼€å§‹ï¼æ¥ä¸‹æ¥å¯ä»¥å°è¯•ï¼š

- é€‰æ‹©ä¸ä½ ä½¿ç”¨åœºæ™¯åŒ¹é…çš„ç¤ºä¾‹ã€‚
- ç»„åˆæ¨¡å—ä»¥æ„å»ºæ›´æ™ºèƒ½ã€æ›´æŒä¹…çš„æ™ºèƒ½ä½“ï¼

è¿˜éœ€è¦æ›´å¤šå¸®åŠ©ï¼Ÿ
æŸ¥çœ‹ API æ–‡æ¡£æˆ–è´¡çŒ®ä½ è‡ªå·±çš„ç¤ºä¾‹å§ï¼

